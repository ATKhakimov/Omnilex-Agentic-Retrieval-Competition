{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct Generation Baseline for Omnilex Legal Retrieval\n",
    "\n",
    "This notebook implements a **direct generation approach** where we prompt a local LLM to generate Swiss legal citations based on the query.\n",
    "\n",
    "## Approach\n",
    "1. Load a local LLM (GGUF format via llama-cpp-python)\n",
    "2. For each query, prompt the LLM to directly generate relevant citations\n",
    "3. Parse and normalize the generated citations\n",
    "4. Create submission file\n",
    "\n",
    "## Requirements\n",
    "- llama-cpp-python (optional - runs in mock mode if not installed)\n",
    "- A GGUF model file (optional - uses mock responses for demonstration if not available)\n",
    "- pandas, tqdm\n",
    "\n",
    "**Note**: This notebook runs in \"mock mode\" if llama-cpp-python is not installed or no model file is available, generating placeholder citations for demonstration purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: Local\n",
      "Dataset mode: val\n",
      "Query file: /home/arijo/Omnilex-Agentic-Retrieval-Competition/data/val.csv\n",
      "Validation mode: True\n",
      "Data path: /home/arijo/Omnilex-Agentic-Retrieval-Competition/data\n",
      "Model path: /home/arijo/Omnilex-Agentic-Retrieval-Competition/models\n",
      "Output path: /home/arijo/Omnilex-Agentic-Retrieval-Competition/output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "# Choose which dataset to run on: \"val\" or \"test\"\n",
    "DATASET_MODE = \"val\"  # Change to \"test\" for final submission\n",
    "\n",
    "# Detect environment\n",
    "KAGGLE_ENV = \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n",
    "\n",
    "if KAGGLE_ENV:\n",
    "    # Kaggle paths\n",
    "    DATA_PATH = Path(\"/kaggle/input/omnilex-data\")\n",
    "    MODEL_PATH = Path(\"/kaggle/input/llama-model\")\n",
    "    OUTPUT_PATH = Path(\"/kaggle/working\")\n",
    "    sys.path.insert(0, \"/kaggle/input/omnilex-utils\")\n",
    "else:\n",
    "    # Local development paths\n",
    "    REPO_ROOT = Path(\".\").resolve().parent\n",
    "    DATA_PATH = REPO_ROOT / \"data\"\n",
    "    MODEL_PATH = REPO_ROOT / \"models\"\n",
    "    OUTPUT_PATH = REPO_ROOT / \"output\"\n",
    "    sys.path.insert(0, str(REPO_ROOT / \"src\"))\n",
    "\n",
    "# Derived paths based on DATASET_MODE\n",
    "QUERY_FILE = DATA_PATH / f\"{DATASET_MODE}.csv\"\n",
    "IS_VALIDATION_MODE = DATASET_MODE == \"val\"\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Environment: {'Kaggle' if KAGGLE_ENV else 'Local'}\")\n",
    "print(f\"Dataset mode: {DATASET_MODE}\")\n",
    "print(f\"Query file: {QUERY_FILE}\")\n",
    "print(f\"Validation mode: {IS_VALIDATION_MODE}\")\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Model path: {MODEL_PATH}\")\n",
    "print(f\"Output path: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    # Model settings\n",
    "    \"model_file\": \"mistral-7b-instruct-v0.2.Q4_K_M.gguf\",  # Adjust to your model\n",
    "    \"n_ctx\": 4096,         # Context window\n",
    "    \"n_threads\": 4,        # CPU threads\n",
    "    \"n_gpu_layers\": -1,    # GPU layers (-1 = offload all layers to GPU)\n",
    "    \n",
    "    # Generation settings\n",
    "    \"max_tokens\": 512,\n",
    "    \"temperature\": 0.0,    # Low temperature for consistency\n",
    "    \n",
    "    # Paths\n",
    "    \"test_file\": \"test.csv\",\n",
    "    \"train_file\": \"train.csv\",  # For local evaluation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: /home/arijo/Omnilex-Agentic-Retrieval-Competition/models/mistral-7b-instruct-v0.2.Q4_K_M.gguf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Running on: GPU (all layers offloaded)\n"
     ]
    }
   ],
   "source": [
    "# Try to import llama_cpp, with fallback for environments without it\n",
    "try:\n",
    "    from llama_cpp import Llama\n",
    "    LLAMA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LLAMA_AVAILABLE = False\n",
    "    print(\"llama_cpp not available. Using mock LLM for demonstration.\")\n",
    "\n",
    "llm = None\n",
    "\n",
    "if LLAMA_AVAILABLE:\n",
    "    # Find model file\n",
    "    model_file = MODEL_PATH / CONFIG[\"model_file\"]\n",
    "\n",
    "    if not model_file.exists():\n",
    "        # Try to find any GGUF file\n",
    "        gguf_files = list(MODEL_PATH.glob(\"*.gguf\")) + list(MODEL_PATH.rglob(\"*.gguf\"))\n",
    "        if gguf_files:\n",
    "            model_file = gguf_files[0]\n",
    "            print(f\"Using model: {model_file}\")\n",
    "        else:\n",
    "            print(f\"No model found in {MODEL_PATH}. Using mock LLM for demonstration.\")\n",
    "            model_file = None\n",
    "\n",
    "    if model_file and model_file.exists():\n",
    "        print(f\"Loading model: {model_file}\")\n",
    "        llm = Llama(\n",
    "            model_path=str(model_file),\n",
    "            n_ctx=CONFIG[\"n_ctx\"],\n",
    "            n_threads=CONFIG[\"n_threads\"],\n",
    "            n_gpu_layers=CONFIG[\"n_gpu_layers\"],\n",
    "            verbose=False,\n",
    "        )\n",
    "        print(\"Model loaded successfully!\")\n",
    "        \n",
    "        # Report compute device\n",
    "        if CONFIG[\"n_gpu_layers\"] == -1:\n",
    "            print(\"Running on: GPU (all layers offloaded)\")\n",
    "        elif CONFIG[\"n_gpu_layers\"] > 0:\n",
    "            print(f\"Running on: GPU ({CONFIG['n_gpu_layers']} layers offloaded)\")\n",
    "        else:\n",
    "            print(f\"Running on: CPU ({CONFIG['n_threads']} threads)\")\n",
    "\n",
    "if llm is None:\n",
    "    print(\"Running in mock mode - will generate placeholder citations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Generation Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a Swiss legal citation expert. Output ONLY a Python list of citations.\n",
    "\n",
    "CITATION FORMATS:\n",
    "- Federal laws: \"Art. X ABBREV\" where ABBREV is ZGB, OR, StGB, BV, etc.\n",
    "- Court decisions: \"BGE X Y Z\" or \"BGE X Y Z E. N\" with consideration number\n",
    "\n",
    "OUTPUT FORMAT: Python list like [\"citation1\", \"citation2\", ...]\n",
    "\n",
    "EXAMPLES:\n",
    "\n",
    "Query: What are the requirements for a valid contract under Swiss law?\n",
    "[\"Art. 1 OR\", \"Art. 11 OR\", \"Art. 12 OR\", \"BGE 119 II 449 E. 2\", \"BGE 127 III 248 E. 3.1\"]\n",
    "\n",
    "Query: When can a marriage be annulled in Switzerland?\n",
    "[\"Art. 104 ZGB\", \"Art. 105 ZGB\", \"Art. 106 ZGB\", \"BGE 121 III 38 E. 2b\"]\n",
    "\n",
    "Query: What constitutes negligent homicide under Swiss criminal law?\n",
    "[\"Art. 117 StGB\", \"Art. 12 StGB\", \"BGE 116 IV 306 E. 1a\"]\n",
    "\n",
    "Query: What are the grounds for divorce in Swiss law?\n",
    "[\"Art. 111 ZGB\", \"Art. 112 ZGB\", \"Art. 114 ZGB\", \"Art. 115 ZGB\", \"BGE 130 III 585 E. 2.1\"]\n",
    "\n",
    "Query: How is inheritance distributed under Swiss law?\n",
    "[\"Art. 457 ZGB\", \"Art. 462 ZGB\", \"Art. 471 ZGB\", \"BGE 132 III 305 E. 3.2\"]\n",
    "\n",
    "Now answer:\"\"\"\n",
    "\n",
    "# Common Swiss law abbreviations for regex matching\n",
    "LAW_ABBREVS = (\n",
    "    \"ZGB|OR|StGB|BV|SchKG|ZPO|StPO|BGG|VwVG|IPRG|KG|DSG|MSchG|URG|PatG|\"\n",
    "    \"DesG|UWG|PrSG|FINMAG|BankG|VAG|KAG|GwG|BEHG|FinfraG|FIDLEG|FINIG|\"\n",
    "    \"ATSG|AHV|IV|EO|ALV|KVG|UVG|BVG|ArG|GlG|USG|RPG|WaG|JSG|TSchG|\"\n",
    "    \"LwG|PBG|EBG|SVG|LFG|SebG|SpG|BoeB|EMRK|SR|AS|BBl|ParlG|RVOG|RVOV|\"\n",
    "    \"MG|BPG|BPV|VBGÖ|VDSG|MWSTG|DBG|StHG|VStG|StG|ZG|CO|CP|CC|CPC|CPP|\"\n",
    "    \"LEtr|LAsi|LN|LDIP|LCart|LDA|LPM|LBI|LDes|LCD|LFINMA|LB|LSA|LPCC|\"\n",
    "    \"LBA|LBVM|LIMF|LSFin|LEFin|LAVS|LAI|LAPG|LACI|LAMal|LAA|LPP|LTr|\"\n",
    "    \"LEg|LPD|LPE|LAT|LFo|LChP|LPN|LAgr|LTV|LCdF|LNA|LPTh|LTAF|LTF\"\n",
    ")\n",
    "\n",
    "\n",
    "def extract_citations(raw_output: str) -> list[str]:\n",
    "    \"\"\"Extract citations from raw LLM output using regex patterns.\"\"\"\n",
    "    import re\n",
    "\n",
    "    citations = []\n",
    "\n",
    "    # Pattern for BGE citations: BGE 141 II 345 E. 3.2\n",
    "    # Matches: BGE + volume + part (roman) + page + optional consideration\n",
    "    bge_pattern = r'BGE\\s+(\\d+)\\s+([IVX]+[a-z]?)\\s+(\\d+)(?:\\s+E\\.\\s*([\\d.a-z/]+))?'\n",
    "    for match in re.finditer(bge_pattern, raw_output):\n",
    "        vol, part, page, consid = match.groups()\n",
    "        if consid:\n",
    "            citations.append(f\"BGE {vol} {part} {page} E. {consid}\")\n",
    "        else:\n",
    "            citations.append(f\"BGE {vol} {part} {page}\")\n",
    "\n",
    "    # Pattern for Art. citations with Abs./lit./Ziff.\n",
    "    # Matches: Art. 221 Abs. 1 lit. b StPO, Art. 364 Abs. 1 OR, Art. 1 ZGB\n",
    "    art_pattern = rf'Art\\.?\\s*(\\d+[a-z]?)(?:\\s+(Abs\\.?\\s*\\d+))?(?:\\s+(lit\\.?\\s*[a-z]))?(?:\\s+(Ziff\\.?\\s*\\d+))?\\s+({LAW_ABBREVS})\\b'\n",
    "    for match in re.finditer(art_pattern, raw_output, re.IGNORECASE):\n",
    "        art_num, abs_part, lit_part, ziff_part, abbrev = match.groups()\n",
    "        parts = [f\"Art. {art_num}\"]\n",
    "        if abs_part:\n",
    "            # Normalize \"Abs1\" or \"Abs 1\" to \"Abs. 1\"\n",
    "            abs_normalized = re.sub(r'Abs\\.?\\s*', 'Abs. ', abs_part)\n",
    "            parts.append(abs_normalized.strip())\n",
    "        if lit_part:\n",
    "            lit_normalized = re.sub(r'lit\\.?\\s*', 'lit. ', lit_part)\n",
    "            parts.append(lit_normalized.strip())\n",
    "        if ziff_part:\n",
    "            ziff_normalized = re.sub(r'Ziff\\.?\\s*', 'Ziff. ', ziff_part)\n",
    "            parts.append(ziff_normalized.strip())\n",
    "        parts.append(abbrev.upper())\n",
    "        citations.append(\" \".join(parts))\n",
    "\n",
    "    # Remove duplicates while preserving order\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    for c in citations:\n",
    "        if c not in seen:\n",
    "            seen.add(c)\n",
    "            unique.append(c)\n",
    "\n",
    "    return unique\n",
    "\n",
    "\n",
    "def generate_citations(query: str) -> list[str]:\n",
    "    \"\"\"Generate citations using direct LLM prompting.\"\"\"\n",
    "    if llm is None:\n",
    "        raise RuntimeError(\"LLM not loaded - please ensure model is available\")\n",
    "\n",
    "    prompt = f\"[INST] {SYSTEM_PROMPT}\\n\\nQuery: {query} [/INST]\"\n",
    "\n",
    "    response = llm(\n",
    "        prompt,\n",
    "        max_tokens=CONFIG[\"max_tokens\"],\n",
    "        temperature=CONFIG[\"temperature\"],\n",
    "        stop=[\"[INST]\", \"</s>\", \"Query:\", \"\\n\\n\"],\n",
    "    )\n",
    "\n",
    "    raw_output: str = response[\"choices\"][0][\"text\"].strip()  # type: ignore[index]\n",
    "    print(f\"Raw output: {raw_output}\\n\")\n",
    "\n",
    "    # Parse Python list format first\n",
    "    import re\n",
    "    import ast\n",
    "    \n",
    "    citations = []\n",
    "    \n",
    "    # Try to parse as Python list\n",
    "    try:\n",
    "        list_match = re.search(r'\\[.*?\\]', raw_output, re.DOTALL)\n",
    "        if list_match:\n",
    "            parsed = ast.literal_eval(list_match.group())\n",
    "            if isinstance(parsed, list):\n",
    "                # Extract citations from parsed list items\n",
    "                for item in parsed:\n",
    "                    item_str = str(item).strip()\n",
    "                    # Extract citations from each item (may have descriptions in parens)\n",
    "                    extracted = extract_citations(item_str)\n",
    "                    citations.extend(extracted)\n",
    "    except (ValueError, SyntaxError):\n",
    "        pass\n",
    "    \n",
    "    # If no citations found from list parsing, try extracting from full output\n",
    "    if not citations:\n",
    "        citations = extract_citations(raw_output)\n",
    "\n",
    "    return citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the requirements for a valid contract under Swiss law?\n",
      "Raw output: [\"Art. 1 OR\", \"Art. 11 OR\", \"Art. 12\"]\n",
      "\n",
      "\n",
      "Generated citations:\n",
      "  - Art. 1 OR\n",
      "  - Art. 11 OR\n"
     ]
    }
   ],
   "source": [
    "# Test generation with a sample query\n",
    "test_query = \"What are the requirements for a valid contract under Swiss law?\"\n",
    "print(f\"Query: {test_query}\")\n",
    "raw_citations = generate_citations(test_query)\n",
    "print(\"\\nGenerated citations:\")\n",
    "for c in raw_citations:\n",
    "    print(f\"  - {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 queries from /home/arijo/Omnilex-Agentic-Retrieval-Competition/data/val.csv\n",
      "Columns: ['query_id', 'query', 'gold_citations']\n",
      "Gold citations available for evaluation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>gold_citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val_001</td>\n",
       "      <td>May a court lawfully order a three‑month exten...</td>\n",
       "      <td>Art. 390 Abs. 2 StPO;Art. 393 Abs. 1 StPO;Art....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val_002</td>\n",
       "      <td>A claimant holding a national vocational diplo...</td>\n",
       "      <td>Art. 21 Abs. 4 ATSG;BGE 134 V 231 E. 5.1;Art. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val_003</td>\n",
       "      <td>A. Rivera, a Peruvian national born in 1994 an...</td>\n",
       "      <td>Art. 29 Abs. 2 BV;BGE 145 I 167 E. 4.1;1B_195/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val_004</td>\n",
       "      <td>Mr. Dalton, born in 1941 and resident in a sma...</td>\n",
       "      <td>Art. 20 Abs. 2 OR;Art. 505 Abs. 1 ZGB;Art. 469...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val_005</td>\n",
       "      <td>A parent, separated from their co-parent since...</td>\n",
       "      <td>Art. 100 Abs. 1 BGG;BGE 131 III 209 E. 5;BGE 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id                                              query  \\\n",
       "0  val_001  May a court lawfully order a three‑month exten...   \n",
       "1  val_002  A claimant holding a national vocational diplo...   \n",
       "2  val_003  A. Rivera, a Peruvian national born in 1994 an...   \n",
       "3  val_004  Mr. Dalton, born in 1941 and resident in a sma...   \n",
       "4  val_005  A parent, separated from their co-parent since...   \n",
       "\n",
       "                                      gold_citations  \n",
       "0  Art. 390 Abs. 2 StPO;Art. 393 Abs. 1 StPO;Art....  \n",
       "1  Art. 21 Abs. 4 ATSG;BGE 134 V 231 E. 5.1;Art. ...  \n",
       "2  Art. 29 Abs. 2 BV;BGE 145 I 167 E. 4.1;1B_195/...  \n",
       "3  Art. 20 Abs. 2 OR;Art. 505 Abs. 1 ZGB;Art. 469...  \n",
       "4  Art. 100 Abs. 1 BGG;BGE 131 III 209 E. 5;BGE 1...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load queries from the configured query file\n",
    "if not QUERY_FILE.exists():\n",
    "    raise FileNotFoundError(f\"Query file not found: {QUERY_FILE}\")\n",
    "\n",
    "test_df = pd.read_csv(QUERY_FILE)\n",
    "\n",
    "print(f\"Loaded {len(test_df)} queries from {QUERY_FILE}\")\n",
    "print(f\"Columns: {list(test_df.columns)}\")\n",
    "\n",
    "if IS_VALIDATION_MODE and \"gold_citations\" in test_df.columns:\n",
    "    print(f\"Gold citations available for evaluation\")\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01034c4e08a44c4a9621368f0d1821f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating predictions:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output: [\"BGE _____ _ _ _ E. _ (decision on extension of pre-trial detention under Art. 221 Abs. 1 lit. b StPO in light of the principle of proportionality)\"]\n",
      "\n",
      "Raw output: [\"BGE not yet available for this specific case\"]\n",
      "\n",
      "Raw output: This query involves a specific legal case and does not directly ask about Swiss law requirements or court decisions. However, if we assume that the query is asking about the legal justification of pretrial detention under Swiss law, the following citations could be relevant:\n",
      "\n",
      "Raw output: [\"BGE 141 II 345 E. 3.2 (testamentary capacity and holographic will)\", \"Art. 472 ZGB (formal requirements for holographic will)\", \"BGE 138 III 178 E. 2 (suspicion of third-party intervention)\", \"BGE 132 III 305 E. 2.1 (language comprehension and vocabulary)\"]\n",
      "\n",
      "Raw output: This query involves a specific legal situation and does not directly relate to Swiss law requirements or court decisions. Therefore, it cannot be answered with a simple list of citations. Instead, I would recommend consulting relevant case law and statutes related to child custody, visitation rights, and the best interests of the child in the Swiss legal system. Here are some potential citations that might be relevant:\n",
      "\n",
      "Raw output: [\"BGE _____ _____ _____, E. N (forthcoming case law on the applicability of Art. 364 Abs. 1 OR or Art. 248 Abs. 1 OR in this factual scenario, with a focus on the standard of care for a professional favor)\"\\_,\n",
      "\n",
      "Raw output: [\"Art. 451 ZGB (testamentary capacity)\", \"Art. 452 ZGB (donative intent)\", \"Art. 453 ZGB (transfer/delivery)\", \"Art. 454 ZGB (acceptance)\", \"Art. 455 ZGB (exclusive physical control)\", \"Art. 456 ZGB (donation causa mortis)\", \"BGE 138 III 345 E. 3 (Art. 4519 CPLR)\", \"BGE 139 II 567 E. 2.1 (photocopy of deed)\", \"BGE 140 III 678 E. 3.2 (Mr. Collins' U.S. testimony)\", \"Art. 934 ZGB (lack of good faith)\", \"Art. 936 ZGB (negligence)\"]\n",
      "\n",
      "Raw output: This query involves a complex factual situation and multiple legal issues, including potential conflicts of interest, breach of fiduciary duties, and contractual disputes. To provide a definitive answer, a thorough analysis of the applicable Swiss laws and court decisions would be necessary. Based on the provided information, the following citations could be relevant:\n",
      "\n",
      "Raw output: This query involves several legal aspects, including family law, criminal law, and enforcement law. Here are the relevant citations:\n",
      "\n",
      "Raw output: [\"BGE 145 II ---- E. ----\", \"Art. 12 StGB (forgery)\", \"Art. 13 StGB (fraud)\", \"Art. 114 ZGB (divorce of contract)\", \"BGE 133 III ---- E. ---- (contractual clauses and exemptions)\", \"BGE 138 II ---- E. ---- (currency conversion and pleading in court)\"]\n",
      "\n",
      "\n",
      "Generated predictions for 10 queries\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Generate predictions\n",
    "predictions = []\n",
    "\n",
    "assert test_df is not None, \"test_df must be loaded before generating predictions\"\n",
    "\n",
    "for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Generating predictions\"):\n",
    "    query_id = row[\"query_id\"]\n",
    "    query_text = row[\"query\"]\n",
    "\n",
    "    # Generate citations using regex extraction (no external normalizer needed)\n",
    "    raw_citations = generate_citations(query_text)\n",
    "\n",
    "    # Use \" \" (single space) when no citations found, otherwise join with \";\"\n",
    "    predicted = \";\".join(raw_citations) if raw_citations else \" \"\n",
    "\n",
    "    predictions.append({\n",
    "        \"query_id\": query_id,\n",
    "        \"predicted_citations\": predicted,\n",
    "    })\n",
    "\n",
    "print(f\"\\nGenerated predictions for {len(predictions)} queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>predicted_citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val_001</td>\n",
       "      <td>Art. 221 Abs. 1 lit. b STPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val_002</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val_003</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val_004</td>\n",
       "      <td>BGE 141 II 345 E. 3.2;Art. 472 ZGB;BGE 138 III...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val_005</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>val_006</td>\n",
       "      <td>Art. 364 Abs. 1 OR;Art. 248 Abs. 1 OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>val_007</td>\n",
       "      <td>Art. 451 ZGB;Art. 452 ZGB;Art. 453 ZGB;Art. 45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>val_008</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>val_009</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>val_010</td>\n",
       "      <td>Art. 12 STGB;Art. 13 STGB;Art. 114 ZGB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id                                predicted_citations\n",
       "0  val_001                        Art. 221 Abs. 1 lit. b STPO\n",
       "1  val_002                                                   \n",
       "2  val_003                                                   \n",
       "3  val_004  BGE 141 II 345 E. 3.2;Art. 472 ZGB;BGE 138 III...\n",
       "4  val_005                                                   \n",
       "5  val_006              Art. 364 Abs. 1 OR;Art. 248 Abs. 1 OR\n",
       "6  val_007  Art. 451 ZGB;Art. 452 ZGB;Art. 453 ZGB;Art. 45...\n",
       "7  val_008                                                   \n",
       "8  val_009                                                   \n",
       "9  val_010             Art. 12 STGB;Art. 13 STGB;Art. 114 ZGB"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview predictions\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: /home/arijo/Omnilex-Agentic-Retrieval-Competition/output/submission.csv\n",
      "Total predictions: 10\n",
      "\n",
      "Sample submission:\n",
      "  query_id                                predicted_citations\n",
      "0  val_001                        Art. 221 Abs. 1 lit. b STPO\n",
      "1  val_002                                                   \n",
      "2  val_003                                                   \n",
      "3  val_004  BGE 141 II 345 E. 3.2;Art. 472 ZGB;BGE 138 III...\n",
      "4  val_005                                                   \n"
     ]
    }
   ],
   "source": [
    "# Save submission\n",
    "submission_path = OUTPUT_PATH / \"submission.csv\"\n",
    "predictions_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"Submission saved to: {submission_path}\")\n",
    "print(f\"Total predictions: {len(predictions_df)}\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample submission:\")\n",
    "print(predictions_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This baseline notebook demonstrates a simple direct generation approach:\n",
    "\n",
    "1. **Prompt engineering**: We use a structured prompt that asks the LLM to generate Swiss legal citations in standard format.\n",
    "\n",
    "2. **Citation normalization**: The generated citations are normalized to canonical form for consistent evaluation.\n",
    "\n",
    "3. **Limitations**:\n",
    "   - The LLM may hallucinate non-existent citations\n",
    "   - No access to actual legal documents for verification\n",
    "   - Relies entirely on the LLM's training data knowledge\n",
    "\n",
    "For better results, see the **Agentic Retrieval Baseline** notebook which uses search tools to ground the generation in actual legal documents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
